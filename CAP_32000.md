  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

### MÉTODO DO ENXAME DE PARTÍCULAS

<p align="justify">
O método de Enxame de Partículas (em inglês <i>Particle Swarm Optimizatio</i>-PSO) foi proposto por James Kennedy e Russell Elberthart em 1995 [<font color="red">EULLER AQUI VOCÊ TEM QUE JÁ CITAR O ARTIGO DO PSO O ORIGINAL COLOQUE COMO URL O LINK DO ARTIGO VOU TE DAR UM EXEMPLO VEJA A FRENTE</font>] <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.05319.pdf">[1]</a>. O Enxame de Partículas ou <b>PSO</b> é um algoritmo metaheurístico baseado em inteligência de enxames que busca simular o comportamento de pássaros e cardume de peixes em busca de alimentos, cada um desses animais são chamados de partícula no método computacional. A particula possue duas propriedades principais que são: (a) a sua posição (\(x_{i}\)); e (b) sua velocidade (\(v_{i}\)), ambas representadas vetorialmente em um espaço \(n\)-dimensional [Iraj Koohi e Voicu Z. Groza <font color="red">EULLER AQUI TROCAR O NOME INTEIRO DOS CARAS POR NÚMERO....ENTÃO NOSSAS REFERÊNCIAS DEVEM SER TODAS NUMÉRICAS 1 2 3 4 5 E ASSIM POR DIANTE COMO FOI NO RELATÓRIO DE IC</font>]. Além disso o método possui uma espécie de memória que armazena um histórico das melhores posições (em relação à aptidão) no espaço \(n\)-dimensional. O histórico de armazenamento relativo a cada partícula é denominado de \( pb \) (em inglês <i>personal best</i>) e o melhor individuo do enxame também terá sua posição armazenada sendo chamado de \( gb \) (em inglês <i>global best</i>). A posição (\(x_{i}\)) e a velocidade (\(v_{i}\)) são modificadas com base nas equações (1) e (2).
</p>

<p align="justify">
\( v_{i}^{t+1} = w . v_{i}^{t} + c_1 . r_1 . (pb_{i}^{t} - x_{i}^{t}) + c_2 . r_2 . (gb_{i}^{t} - x_{i}^{t}) \) <br>  
\( x_{ij}^{t+1} = x_{ij}^{t} + v_{ij} \) <br>
Onde:<br>
<ul>
<li>\( v_{i}^{t} \) é a velocidade da partícula \(i\) na iteração \(t\).</li>
<li>\( x_{i}^{t} \) é a posição da partícula \(i\) na iteração \(t\).</li>
<li>\( x_{i}^{t+1} \) é a posição da partícula \(i\) na iteração \(t+1\).</li>
<li>\( w \) é o coeficiente de inércia.</li>
<li>\( c_1 \) é o fator de aprendizado cognitivo.</li>
<li>\( c_2 \) é o fator de aprendizadp social.</li>
<li>\( r_1 \) e \( r_2 \) são números aleatórios em entre 0 e 1.</li>
</ul>
Os fatores de aprendizagem cognitivos e social foram criados para estebalecer um balanço (em inglês <i>trade off</i> no ato da partícula caminhar pelo espaço de busca procurando a melhor solução. Kennedy e Elberthart [1<font color="red">EULLER LEMBRAR DE COLOCAR O HYPERLINK DESSE TEXTO</font>] afirmam que esses coeficientes podem variar de 0 até 4 e quando somados (\( c_1 + c_2\)) a recomendação é que totalizem o valor 4. 
Além desse balanço na escolha do fator \( c_1 \) e \( c_2 \) a velocidade deve ser fixada em uma faixa, semelhante as restrições laterais (\(x_{min}\) e \(x_{max}\)) nas variáveis de projeto \(x\). Tal fato de criar imposições laterais no vetor de velocidades contribui na estabilidade do método de otimização.
</p>

O funcionamento do algoritmo PSO está logo abaixo:

``` python
    Inicio Algoritmo
        Para i - 0 até n faça
            Para j de 1 a d faça
                x:-rand(min, max)
                v:-rand(0, vmax)
            Fim Para
            p:-x
            pbest - f(pi)
            Se pbest < vbest então
                gbest:= pbest
            Fim Se
        Fim Para
        Para i= 0 até n faça
            Para j = 0 até m faça
                v := w*v + c1*rand()*(pbest-x) + c2*rand()*(gbest-x)
                x:= v + x
            Fim Para
            fitness := f(x)
            Se fitness < pbest então
                pbest := fitness
                Se fitness < vbest então
                    gbest[i]:= fitness
                Fim Se
            Fim Se
        Fim Para
    Fim Algoritmo
```

